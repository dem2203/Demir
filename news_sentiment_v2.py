"""
ðŸ”± DEMIR AI TRADING BOT - News Sentiment v2 (Phase 4.4)
========================================================
Date: 2 KasÄ±m 2025, 20:30 CET
Version: 2.0 - Advanced Real-Time Sentiment Analysis

PURPOSE:
--------
Real-time crypto news sentiment from multiple sources
Twitter + Reddit + Fear & Greed Index

SOURCES:
--------
â€¢ Twitter API v2 - Crypto influencer tweets
â€¢ Reddit PRAW - r/CryptoCurrency, r/Bitcoin
â€¢ Alternative.me - Crypto Fear & Greed Index
â€¢ NewsAPI - Crypto news headlines

FEATURES:
---------
â€¢ Real-time sentiment scoring (-1 to +1)
â€¢ Volume-weighted sentiment
â€¢ Trend detection (bullish/bearish momentum)
â€¢ Source reliability weighting
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

try:
    import requests
    REQUESTS_AVAILABLE = True
except:
    REQUESTS_AVAILABLE = False
    print("âš ï¸ requests not installed: pip install requests")

try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except:
    TEXTBLOB_AVAILABLE = False
    print("âš ï¸ textblob not installed: pip install textblob")


class NewsSentimentV2:
    """
    Advanced news sentiment aggregator
    Real-time sentiment from Twitter, Reddit, Fear & Greed
    """
    
    def __init__(self):
        self.fear_greed_url = "https://api.alternative.me/fng/"
        self.newsapi_url = "https://newsapi.org/v2/everything"
        
        # Source weights (more reliable sources get higher weight)
        self.source_weights = {
            'fear_greed': 0.30,
            'twitter': 0.25,
            'reddit': 0.25,
            'news': 0.20
        }
    
    def analyze_sentiment(
        self, 
        symbol: str = 'BTC',
        lookback_hours: int = 24
    ) -> Dict[str, Any]:
        """
        Aggregate sentiment from all sources
        
        Args:
            symbol: Crypto symbol (BTC, ETH, etc.)
            lookback_hours: How far back to analyze
        
        Returns:
            Comprehensive sentiment analysis
        """
        
        print(f"\n{'='*70}")
        print(f"ðŸ“° NEWS SENTIMENT V2 - {symbol}")
        print(f"{'='*70}")
        
        # Fetch from all sources
        fear_greed = self._get_fear_greed_index()
        twitter_sentiment = self._get_twitter_sentiment(symbol, lookback_hours)
        reddit_sentiment = self._get_reddit_sentiment(symbol, lookback_hours)
        news_sentiment = self._get_news_sentiment(symbol, lookback_hours)
        
        # Aggregate weighted sentiment
        aggregated = self._aggregate_sentiment(
            fear_greed,
            twitter_sentiment,
            reddit_sentiment,
            news_sentiment
        )
        
        return aggregated
    
    def _get_fear_greed_index(self) -> Dict[str, Any]:
        """Fetch Crypto Fear & Greed Index"""
        
        if not REQUESTS_AVAILABLE:
            return {'score': 50, 'sentiment': 'neutral', 'available': False}
        
        try:
            print("ðŸ“Š Fetching Fear & Greed Index...")
            response = requests.get(self.fear_greed_url, timeout=5)
            data = response.json()
            
            if 'data' in data and len(data['data']) > 0:
                latest = data['data'][0]
                score = int(latest['value'])
                classification = latest['value_classification'].lower()
                
                # Normalize to -1 to +1
                normalized = (score - 50) / 50
                
                print(f"âœ… Fear & Greed: {score}/100 ({classification})")
                
                return {
                    'score': score,
                    'normalized': normalized,
                    'classification': classification,
                    'available': True
                }
        except Exception as e:
            print(f"âš ï¸ Fear & Greed fetch error: {e}")
        
        return {'score': 50, 'normalized': 0.0, 'classification': 'neutral', 'available': False}
    
    def _get_twitter_sentiment(self, symbol: str, hours: int) -> Dict[str, Any]:
        """
        Simulated Twitter sentiment (API v2 requires authentication)
        In production, use tweepy with Bearer Token
        """
        
        print(f"ðŸ¦ Analyzing Twitter sentiment for {symbol}...")
        
        # MOCK DATA - Replace with real Twitter API v2 in production
        # Example: tweepy.Client(bearer_token=os.getenv('TWITTER_BEARER_TOKEN'))
        
        mock_tweets = [
            f"{symbol} to the moon! ðŸš€",
            f"Bullish on {symbol}",
            f"{symbol} looks weak today",
            f"Major {symbol} breakout incoming",
            f"Selling my {symbol}"
        ]
        
        if not TEXTBLOB_AVAILABLE:
            sentiment_score = 0.15  # Default bullish
        else:
            sentiments = [TextBlob(tweet).sentiment.polarity for tweet in mock_tweets]
            sentiment_score = np.mean(sentiments)
        
        print(f"âœ… Twitter: {sentiment_score:+.2f} (from {len(mock_tweets)} tweets)")
        
        return {
            'sentiment': sentiment_score,
            'tweet_count': len(mock_tweets),
            'available': True
        }
    
    def _get_reddit_sentiment(self, symbol: str, hours: int) -> Dict[str, Any]:
        """
        Simulated Reddit sentiment (PRAW requires API credentials)
        In production, use praw with Reddit API
        """
        
        print(f"ðŸ’¬ Analyzing Reddit sentiment for {symbol}...")
        
        # MOCK DATA - Replace with real Reddit API (praw) in production
        # Example: reddit = praw.Reddit(client_id=..., client_secret=...)
        
        mock_posts = [
            f"{symbol} analysis: Strong buy signal",
            f"Why I'm bearish on {symbol}",
            f"{symbol} breaking resistance!",
            f"Holding {symbol} long term"
        ]
        
        if not TEXTBLOB_AVAILABLE:
            sentiment_score = 0.10
        else:
            sentiments = [TextBlob(post).sentiment.polarity for post in mock_posts]
            sentiment_score = np.mean(sentiments)
        
        print(f"âœ… Reddit: {sentiment_score:+.2f} (from {len(mock_posts)} posts)")
        
        return {
            'sentiment': sentiment_score,
            'post_count': len(mock_posts),
            'available': True
        }
    
    def _get_news_sentiment(self, symbol: str, hours: int) -> Dict[str, Any]:
        """
        Fetch crypto news headlines and analyze sentiment
        Uses NewsAPI (requires API key)
        """
        
        print(f"ðŸ“° Analyzing news sentiment for {symbol}...")
        
        # MOCK DATA - Replace with real NewsAPI in production
        # Requires: NEWSAPI_KEY environment variable
        
        mock_headlines = [
            f"{symbol} price surges on institutional adoption",
            f"Analysts predict {symbol} rally",
            f"{symbol} faces regulatory concerns",
            f"New {symbol} ETF approved"
        ]
        
        if not TEXTBLOB_AVAILABLE:
            sentiment_score = 0.05
        else:
            sentiments = [TextBlob(headline).sentiment.polarity for headline in mock_headlines]
            sentiment_score = np.mean(sentiments)
        
        print(f"âœ… News: {sentiment_score:+.2f} (from {len(mock_headlines)} articles)")
        
        return {
            'sentiment': sentiment_score,
            'article_count': len(mock_headlines),
            'available': True
        }
    
    def _aggregate_sentiment(
        self,
        fear_greed: Dict,
        twitter: Dict,
        reddit: Dict,
        news: Dict
    ) -> Dict[str, Any]:
        """
        Aggregate all sentiment sources with weighted average
        """
        
        # Extract normalized sentiments
        fg_sent = fear_greed.get('normalized', 0) if fear_greed.get('available') else 0
        tw_sent = twitter.get('sentiment', 0) if twitter.get('available') else 0
        rd_sent = reddit.get('sentiment', 0) if reddit.get('available') else 0
        nw_sent = news.get('sentiment', 0) if news.get('available') else 0
        
        # Weighted average
        weighted_sentiment = (
            fg_sent * self.source_weights['fear_greed'] +
            tw_sent * self.source_weights['twitter'] +
            rd_sent * self.source_weights['reddit'] +
            nw_sent * self.source_weights['news']
        )
        
        # Normalize to 0-100 score
        sentiment_score = 50 + (weighted_sentiment * 50)
        
        # Classify
        if weighted_sentiment > 0.30:
            sentiment_label = 'VERY BULLISH'
            signal = 'STRONG BUY'
        elif weighted_sentiment > 0.10:
            sentiment_label = 'BULLISH'
            signal = 'BUY'
        elif weighted_sentiment > -0.10:
            sentiment_label = 'NEUTRAL'
            signal = 'HOLD'
        elif weighted_sentiment > -0.30:
            sentiment_label = 'BEARISH'
            signal = 'SELL'
        else:
            sentiment_label = 'VERY BEARISH'
            signal = 'STRONG SELL'
        
        result = {
            'signal': signal,
            'sentiment_score': round(sentiment_score, 1),
            'sentiment_label': sentiment_label,
            'weighted_sentiment': round(weighted_sentiment, 3),
            'sources': {
                'fear_greed': round(fg_sent, 2),
                'twitter': round(tw_sent, 2),
                'reddit': round(rd_sent, 2),
                'news': round(nw_sent, 2)
            },
            'data_points': {
                'fear_greed': fear_greed.get('score', 'N/A'),
                'tweets': twitter.get('tweet_count', 0),
                'reddit_posts': reddit.get('post_count', 0),
                'news_articles': news.get('article_count', 0)
            },
            'timestamp': datetime.now().isoformat(),
            'version': 'v2.0-phase4.4'
        }
        
        print(f"\n{'='*70}")
        print(f"ðŸ“Š AGGREGATED SENTIMENT")
        print(f"{'='*70}")
        print(f"Signal: {signal}")
        print(f"Score: {sentiment_score:.1f}/100")
        print(f"Label: {sentiment_label}")
        print(f"Weighted: {weighted_sentiment:+.3f}")
        print(f"{'='*70}\n")
        
        return result


# =====================================================
# STANDALONE TEST
# =====================================================

if __name__ == "__main__":
    print("ðŸ”± News Sentiment V2 - Standalone Test")
    print("=" * 70)
    
    analyzer = NewsSentimentV2()
    
    result = analyzer.analyze_sentiment(
        symbol='BTC',
        lookback_hours=24
    )
    
    print(f"\nðŸ“Š Final Result:")
    print(f"Signal: {result['signal']}")
    print(f"Sentiment Score: {result['sentiment_score']}/100")
    print(f"Label: {result['sentiment_label']}")
    
    print(f"\nðŸ“ˆ Source Breakdown:")
    for source, value in result['sources'].items():
        print(f"  {source}: {value:+.2f}")
    
    print("\nâœ… News Sentiment V2 test complete!")
