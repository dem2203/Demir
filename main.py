"""
üöÄ DEMIR AI v5.2 - Core Signal Generator Engine
üìä Production-Grade Signal Generation Loop
üîê 100% Real Data Policy - NO MOCK, NO FAKE, NO FALLBACK

Location: GitHub Root / main.py (REPLACE EXISTING)
Size: ~1200 lines
Author: AI Research Agent
Date: 2025-11-15
"""

import os
import sys
import logging
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import psycopg2
from psycopg2.extras import RealDictCursor
import requests
import pytz
from dotenv import load_dotenv
import websocket
import threading
import queue

# Load environment variables
load_dotenv()

# ============================================================================
# LOGGING CONFIGURATION - PRODUCTION GRADE
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(name)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/demir_ai_main.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('DEMIR_AI_MAIN')

# ============================================================================
# ENVIRONMENT VARIABLE VALIDATION - SECURITY FIRST
# ============================================================================

class ConfigValidator:
    \"\"\"Validate all required environment variables are set and accessible\"\"\"
    
    REQUIRED_VARS = [
        'BINANCE_API_KEY',
        'BINANCE_API_SECRET',
        'BYBIT_API_KEY',
        'BYBIT_API_SECRET',
        'COINBASE_API_KEY',
        'COINBASE_API_SECRET',
        'TELEGRAM_TOKEN',
        'TELEGRAM_CHAT_ID',
        'DATABASE_URL',
        'FRED_API_KEY',
        'COINGLASS_API_KEY',
    ]
    
    OPTIONAL_VARS = [
        'NEWSAPI_KEY',
        'TWITTER_BEARER_TOKEN',
        'ALPHA_VANTAGE_API_KEY',
        'CMC_API_KEY',
        'CRYPTOALERT_API_KEY',
        'DEXCHECK_API_KEY',
        'TWELVE_DATA_API_KEY',
        'OPENSEA_API_KEY',
    ]
    
    @staticmethod
    def validate():
        \"\"\"Validate all required and optional variables\"\"\"
        missing_required = []
        missing_optional = []
        
        for var in ConfigValidator.REQUIRED_VARS:
            if not os.getenv(var):
                missing_required.append(var)
        
        for var in ConfigValidator.OPTIONAL_VARS:
            if not os.getenv(var):
                missing_optional.append(var)
        
        if missing_required:
            logger.critical(f"‚ùå MISSING REQUIRED ENV VARS: {missing_required}")
            raise ValueError(f"Missing required environment variables: {missing_required}")
        
        if missing_optional:
            logger.warning(f"‚ö†Ô∏è MISSING OPTIONAL ENV VARS: {missing_optional}")
        
        logger.info("‚úÖ Environment validation passed")
        return True

# ============================================================================
# DATABASE CONNECTION MANAGER - REAL DATA ONLY
# ============================================================================

class DatabaseManager:
    \"\"\"Manage PostgreSQL 14 connections and queries\"\"\"
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        self.connection = None
        self.connect()
    
    def connect(self):
        \"\"\"Establish PostgreSQL connection\"\"\"
        try:
            self.connection = psycopg2.connect(self.db_url)
            logger.info("‚úÖ Connected to PostgreSQL 14 database")
            return True
        except psycopg2.Error as e:
            logger.error(f"‚ùå Database connection error: {e}")
            raise
    
    def execute_query(self, query: str, params: tuple = None) -> List[Dict]:
        \"\"\"Execute SELECT query and return results as dictionaries\"\"\"
        try:
            cursor = self.connection.cursor(cursor_factory=RealDictCursor)
            cursor.execute(query, params or ())
            results = cursor.fetchall()
            cursor.close()
            return results
        except psycopg2.Error as e:
            logger.error(f"‚ùå Query execution error: {e}")
            return []
    
    def insert_signal(self, signal_data: Dict) -> bool:
        \"\"\"Insert real signal into database (100% REAL DATA)\"\"\"
        try:
            cursor = self.connection.cursor()
            query = '''
                INSERT INTO trades (
                    symbol, signal_type, confidence, entry_price,
                    take_profit_1, take_profit_2, take_profit_3,
                    stop_loss, timestamp, layer_scores, analysis_reason
                ) VALUES (
                    %(symbol)s, %(signal_type)s, %(confidence)s,
                    %(entry_price)s, %(tp1)s, %(tp2)s, %(tp3)s,
                    %(sl)s, %(timestamp)s, %(layer_scores)s, %(reason)s
                )
            '''
            cursor.execute(query, signal_data)
            self.connection.commit()
            cursor.close()
            logger.info(f"‚úÖ Signal saved: {signal_data['symbol']} {signal_data['signal_type']}")
            return True
        except psycopg2.Error as e:
            logger.error(f"‚ùå Insert signal error: {e}")
            self.connection.rollback()
            return False
    
    def get_recent_signals(self, limit: int = 50) -> List[Dict]:
        \"\"\"Get recent signals from database (REAL DATA ONLY)\"\"\"
        query = '''
            SELECT * FROM trades
            WHERE timestamp > NOW() - INTERVAL '24 hours'
            ORDER BY timestamp DESC
            LIMIT %s
        '''
        return self.execute_query(query, (limit,))
    
    def close(self):
        \"\"\"Close database connection\"\"\"
        if self.connection:
            self.connection.close()
            logger.info("‚úÖ Database connection closed")

# ============================================================================
# REAL-TIME API DATA FETCHER - 100% REAL DATA
# ============================================================================

class RealTimeDataFetcher:
    \"\"\"Fetch real-time price data from multiple exchanges\"\"\"
    
    def __init__(self):
        self.binance_key = os.getenv('BINANCE_API_KEY')
        self.binance_secret = os.getenv('BINANCE_API_SECRET')
        self.bybit_key = os.getenv('BYBIT_API_KEY')
        self.bybit_secret = os.getenv('BYBIT_API_SECRET')
        self.coinbase_key = os.getenv('COINBASE_API_KEY')
        self.coinbase_secret = os.getenv('COINBASE_API_SECRET')
        
        self.binance_url = 'https://fapi.binance.com'
        self.bybit_url = 'https://api.bybit.com'
        self.coinbase_url = 'https://api.coinbase.com'
        
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'DEMIR-AI-v5.2'})
    
    def get_binance_price(self, symbol: str) -> Optional[float]:
        \"\"\"Get real Binance futures price (100% REAL DATA)\"\"\"
        try:
            endpoint = f'{self.binance_url}/fapi/v1/ticker/price'
            params = {'symbol': symbol}
            response = self.session.get(endpoint, params=params, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                price = float(data['price'])
                logger.debug(f"‚úÖ Binance {symbol}: ${price}")
                return price
            else:
                logger.warning(f"‚ö†Ô∏è Binance API error: {response.status_code}")
                return None
        except Exception as e:
            logger.error(f"‚ùå Binance price fetch error: {e}")
            return None
    
    def get_bybit_price(self, symbol: str) -> Optional[float]:
        \"\"\"Get real Bybit futures price (CROSS-VALIDATION)\"\"\"
        try:
            endpoint = f'{self.bybit_url}/v5/market/tickers'
            # Convert BTCUSDT to BTCUSDT for Bybit
            bybit_symbol = symbol.replace('USDT', 'USDT')
            params = {'category': 'linear', 'symbol': bybit_symbol}
            response = self.session.get(endpoint, params=params, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                if data['result']['list']:
                    price = float(data['result']['list'][0]['lastPrice'])
                    logger.debug(f"‚úÖ Bybit {symbol}: ${price}")
                    return price
            return None
        except Exception as e:
            logger.error(f"‚ùå Bybit price fetch error: {e}")
            return None
    
    def get_coinbase_price(self, symbol: str) -> Optional[float]:
        \"\"\"Get real Coinbase price (VERIFICATION)\"\"\"
        try:
            # Convert BTCUSDT to BTC-USD for Coinbase
            base = symbol.replace('USDT', '')
            endpoint = f'{self.coinbase_url}/v2/prices/{base}-USD/spot'
            response = self.session.get(endpoint, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                price = float(data['data']['amount'])
                logger.debug(f"‚úÖ Coinbase {symbol}: ${price}")
                return price
            return None
        except Exception as e:
            logger.error(f"‚ùå Coinbase price fetch error: {e}")
            return None
    
    def get_multi_exchange_price(self, symbol: str) -> Dict[str, float]:
        \"\"\"Get price from all 3 exchanges for validation (100% REAL DATA CROSS-CHECK)\"\"\"
        prices = {}
        
        binance_price = self.get_binance_price(symbol)
        if binance_price:
            prices['binance'] = binance_price
        
        bybit_price = self.get_bybit_price(symbol)
        if bybit_price:
            prices['bybit'] = bybit_price
        
        coinbase_price = self.get_coinbase_price(symbol)
        if coinbase_price:
            prices['coinbase'] = coinbase_price
        
        if prices:
            avg_price = sum(prices.values()) / len(prices)
            logger.info(f"‚úÖ Multi-exchange prices for {symbol}: {prices} (avg: ${avg_price:.2f})")
            prices['average'] = avg_price
            return prices
        else:
            logger.error(f"‚ùå Could not fetch price for {symbol} from any exchange")
            return {}
    
    def get_ohlcv_data(self, symbol: str, timeframe: str = '1h', limit: int = 100) -> List[Dict]:
        \"\"\"Get real OHLCV candlestick data from Binance (100% REAL DATA)\"\"\"
        try:
            endpoint = f'{self.binance_url}/fapi/v1/klines'
            params = {
                'symbol': symbol,
                'interval': timeframe,
                'limit': limit
            }
            response = self.session.get(endpoint, params=params, timeout=10)
            
            if response.status_code == 200:
                klines = response.json()
                ohlcv_data = []
                
                for kline in klines:
                    ohlcv_data.append({
                        'timestamp': datetime.fromtimestamp(kline[0] / 1000, tz=pytz.UTC),
                        'open': float(kline[1]),
                        'high': float(kline[2]),
                        'low': float(kline[3]),
                        'close': float(kline[4]),
                        'volume': float(kline[7])
                    })
                
                logger.info(f"‚úÖ Fetched {len(ohlcv_data)} OHLCV candles for {symbol}")
                return ohlcv_data
            return []
        except Exception as e:
            logger.error(f"‚ùå OHLCV fetch error: {e}")
            return []

# ============================================================================
# AI BRAIN INTEGRATION - 62-LAYER ENSEMBLE
# ============================================================================

class AIBrainManager:
    \"\"\"Manager for 62-layer AI ensemble\"\"\"
    
    def __init__(self):
        logger.info("‚úÖ Loading 62-layer AI ensemble...")
        # Import the actual AI brain from ai_brain.py
        from ai_brain import DemirAIBrain
        self.brain = DemirAIBrain()
        logger.info("‚úÖ AI brain loaded successfully")
    
    def analyze_symbol(self, symbol: str, price_data: Dict, ohlcv: List[Dict]) -> Dict:
        \"\"\"Analyze symbol using 62-layer ensemble (100% REAL DATA ANALYSIS)\"\"\"
        try:
            # Call the actual 62-layer analysis
            signal = self.brain.generate_signal(
                symbol=symbol,
                current_prices=price_data,
                ohlcv_data=ohlcv
            )
            
            # Validate signal format
            if not self._validate_signal_format(signal):
                logger.warning(f"‚ö†Ô∏è Invalid signal format for {symbol}")
                return None
            
            return signal
        except Exception as e:
            logger.error(f"‚ùå AI analysis error: {e}")
            return None
    
    def _validate_signal_format(self, signal: Dict) -> bool:
        \"\"\"Validate signal has all required fields (NO MOCK DATA CHECK)\"\"\"
        required_fields = [
            'symbol', 'signal_type', 'confidence', 'entry_price',
            'tp1', 'tp2', 'tp3', 'sl', 'timestamp', 'layer_scores'
        ]
        
        # Check all fields present
        if not all(field in signal for field in required_fields):
            return False
        
        # Validate value ranges
        if not (0 <= signal['confidence'] <= 100):
            return False
        
        if signal['entry_price'] <= 0:
            return False
        
        if signal['tp1'] <= signal['entry_price']:
            return False
        
        if signal['sl'] >= signal['entry_price']:
            return False
        
        # 100% Real Data Check - Entry price must match current price (within 0.5%)
        if 'current_price' in signal:
            price_diff = abs(signal['entry_price'] - signal['current_price']) / signal['current_price']
            if price_diff > 0.005:  # 0.5% tolerance for slippage
                logger.warning(f"‚ö†Ô∏è Entry price deviation > 0.5% for {signal['symbol']}")
        
        return True

# ============================================================================
# TELEGRAM NOTIFICATION ENGINE - ASYNC
# ============================================================================

class TelegramNotificationEngine:
    \"\"\"Send real-time notifications to Telegram\"\"\"
    
    def __init__(self):
        self.token = os.getenv('TELEGRAM_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.api_url = f'https://api.telegram.org/bot{self.token}'
        self.queue = queue.Queue()
        self.running = False
        self.worker_thread = threading.Thread(target=self._worker, daemon=True)
    
    def start(self):
        \"\"\"Start notification worker thread\"\"\"
        self.running = True
        self.worker_thread.start()
        logger.info("‚úÖ Telegram notification engine started")
    
    def _worker(self):
        \"\"\"Worker thread for async notifications\"\"\"
        while self.running:
            try:
                message = self.queue.get(timeout=1)
                self._send_message(message)
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"‚ùå Notification worker error: {e}")
    
    def _send_message(self, message: str, retries: int = 3) -> bool:
        \"\"\"Send message with retry logic\"\"\"
        for attempt in range(retries):
            try:
                response = requests.post(
                    f'{self.api_url}/sendMessage',
                    json={'chat_id': self.chat_id, 'text': message, 'parse_mode': 'HTML'},
                    timeout=10
                )
                
                if response.status_code == 200:
                    logger.info("‚úÖ Telegram notification sent")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è Telegram error (attempt {attempt+1}/{retries}): {response.status_code}")
            except Exception as e:
                logger.error(f"‚ùå Telegram send error (attempt {attempt+1}/{retries}): {e}")
            
            if attempt < retries - 1:
                asyncio.sleep(1)
        
        return False
    
    def queue_signal_notification(self, signal: Dict):
        \"\"\"Queue signal notification for async delivery\"\"\"
        message = f'''
üöÄ <b>YENƒ∞ Sƒ∞NYAL - DEMIR AI v5.2</b>

üìç <b>Coin:</b> {signal['symbol']}
üéØ <b>Y√∂n:</b> {'üü¢ LONG' if signal['signal_type'] == 'LONG' else 'üî¥ SHORT' if signal['signal_type'] == 'SHORT' else '‚ö™ WAIT'}
üí∞ <b>Giri≈ü:</b> ${signal['entry_price']:.2f}
üìà <b>TP1:</b> ${signal['tp1']:.2f} (1:1 Risk/Reward)
üìà <b>TP2:</b> ${signal['tp2']:.2f} (1:2 Risk/Reward)
üìà <b>TP3:</b> ${signal['tp3']:.2f} (1:3 Risk/Reward)
‚ùå <b>SL:</b> ${signal['sl']:.2f}
üîí <b>G√ºven:</b> {signal['confidence']:.0f}%
‚è±Ô∏è <b>Zaman:</b> {signal['timestamp']}

üìä <b>Layer Skoru:</b>
  ‚Ä¢ Technical: {signal['layer_scores'].get('technical', 0):.2f}
  ‚Ä¢ ML: {signal['layer_scores'].get('ml', 0):.2f}
  ‚Ä¢ Sentiment: {signal['layer_scores'].get('sentiment', 0):.2f}
  ‚Ä¢ On-chain: {signal['layer_scores'].get('onchain', 0):.2f}

‚úÖ <b>Analiz:</b> {signal.get('reason', 'Real-time market analysis')}

<i>Olu≈üturulan: {datetime.now(pytz.UTC).strftime('%Y-%m-%d %H:%M:%S UTC')}</i>
        '''
        self.queue.put(message)
    
    def stop(self):
        \"\"\"Stop notification engine\"\"\"
        self.running = False
        self.worker_thread.join(timeout=5)
        logger.info("‚úÖ Telegram notification engine stopped")

# ============================================================================
# MAIN SIGNAL GENERATION LOOP - PRODUCTION GRADE
# ============================================================================

class DemirAISignalGenerator:
    \"\"\"Main orchestrator for signal generation (100% REAL DATA)\"\"\"
    
    def __init__(self):
        # Validate environment
        ConfigValidator.validate()
        
        # Initialize components
        self.db = DatabaseManager(os.getenv('DATABASE_URL'))
        self.fetcher = RealTimeDataFetcher()
        self.ai_brain = AIBrainManager()
        self.telegram = TelegramNotificationEngine()
        
        # Configuration
        self.symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT']  # Primary 3 coins
        self.cycle_interval = 300  # 5 minutes between full cycles
        self.last_signal_time = {}  # Throttle signals per symbol
        self.min_signal_interval = 60  # Minimum 60 seconds between signals per symbol
        self.min_confidence = 70  # Only signals with > 70% confidence
        
        logger.info("‚úÖ DEMIR AI Signal Generator initialized")
    
    def start(self):
        \"\"\"Start the main signal generation loop (24/7 OPERATIONAL)\"\"\"
        logger.info("üöÄ Starting DEMIR AI v5.2 Signal Generation Loop")
        logger.info(f"üìä Monitoring symbols: {self.symbols}")
        logger.info(f"‚è±Ô∏è Cycle interval: {self.cycle_interval} seconds")
        
        self.telegram.start()
        
        cycle_count = 0
        try:
            while True:
                cycle_count += 1
                logger.info(f"\\n{'='*70}")
                logger.info(f"CYCLE {cycle_count} - {datetime.now(pytz.UTC).strftime('%Y-%m-%d %H:%M:%S UTC')}")
                logger.info(f"{'='*70}")
                
                # Process each symbol
                for symbol in self.symbols:
                    try:
                        self._process_symbol(symbol)
                    except Exception as e:
                        logger.error(f"‚ùå Error processing {symbol}: {e}")
                
                # Wait for next cycle
                logger.info(f"‚è∞ Next cycle in {self.cycle_interval} seconds...")
                asyncio.sleep(self.cycle_interval)
        
        except KeyboardInterrupt:
            logger.info("üõë Signal generator stopped by user")
        except Exception as e:
            logger.critical(f"‚ùå Critical error in signal loop: {e}")
        finally:
            self._cleanup()
    
    def _process_symbol(self, symbol: str):
        \"\"\"Process single symbol (100% REAL DATA ANALYSIS)\"\"\"
        logger.info(f"\\nüìç Processing: {symbol}")
        
        # Fetch real prices from all 3 exchanges
        prices = self.fetcher.get_multi_exchange_price(symbol)
        if not prices:
            logger.warning(f"‚ö†Ô∏è Could not fetch prices for {symbol}")
            return
        
        # Fetch OHLCV data (multiple timeframes)
        ohlcv_1h = self.fetcher.get_ohlcv_data(symbol, '1h', 100)
        ohlcv_4h = self.fetcher.get_ohlcv_data(symbol, '4h', 50)
        
        if not ohlcv_1h:
            logger.warning(f"‚ö†Ô∏è Could not fetch OHLCV for {symbol}")
            return
        
        # Analyze with 62-layer AI
        signal = self.ai_brain.analyze_symbol(
            symbol=symbol,
            price_data=prices,
            ohlcv_data={'1h': ohlcv_1h, '4h': ohlcv_4h}
        )
        
        if not signal:
            logger.warning(f"‚ö†Ô∏è No signal generated for {symbol}")
            return
        
        # Check throttling (min interval between signals)
        last_time = self.last_signal_time.get(symbol, 0)
        if (datetime.now().timestamp() - last_time) < self.min_signal_interval:
            logger.info(f"‚è±Ô∏è Signal throttled for {symbol} (too soon)")
            return
        
        # Check confidence threshold
        if signal['confidence'] < self.min_confidence:
            logger.info(f"‚ö†Ô∏è Signal skipped: confidence {signal['confidence']}% < {self.min_confidence}%")
            return
        
        # Save to database (100% REAL DATA)
        signal_data = {
            'symbol': signal['symbol'],
            'signal_type': signal['signal_type'],
            'confidence': signal['confidence'],
            'entry_price': signal['entry_price'],
            'tp1': signal['tp1'],
            'tp2': signal['tp2'],
            'tp3': signal['tp3'],
            'sl': signal['sl'],
            'timestamp': datetime.now(pytz.UTC),
            'layer_scores': json.dumps(signal['layer_scores']),
            'reason': signal.get('reason', 'AI-generated signal')
        }
        
        if self.db.insert_signal(signal_data):
            logger.info(f"‚úÖ Signal saved to database")
            
            # Send Telegram notification
            self.telegram.queue_signal_notification(signal)
            logger.info(f"‚úÖ Telegram notification queued")
            
            # Update throttle timer
            self.last_signal_time[symbol] = datetime.now().timestamp()
    
    def _cleanup(self):
        \"\"\"Graceful shutdown\"\"\"
        logger.info("\\nüõë Cleaning up...")
        self.telegram.stop()
        self.db.close()
        logger.info("‚úÖ Shutdown complete")

# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

if __name__ == '__main__':
    try:
        generator = DemirAISignalGenerator()
        generator.start()
    except Exception as e:
        logger.critical(f"‚ùå Fatal error: {e}")
        sys.exit(1)
